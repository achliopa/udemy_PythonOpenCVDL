{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 60s 2us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0aeebf6828>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0],cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0aeeb8c208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0],cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = to_categorical(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,Dense,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(28,28,1),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 36s 599us/step - loss: 0.3938 - acc: 0.8596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0aeeb3cac8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_cat_train,verbose=1,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 164us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3147653980970383, 0.8884]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.82      0.81      0.82      1000\n",
      "           3       0.88      0.92      0.90      1000\n",
      "           4       0.81      0.83      0.82      1000\n",
      "           5       0.98      0.96      0.97      1000\n",
      "           6       0.73      0.63      0.68      1000\n",
      "           7       0.95      0.94      0.95      1000\n",
      "           8       0.98      0.97      0.97      1000\n",
      "           9       0.94      0.97      0.96      1000\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
